{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important reminder\n",
    "\n",
    "Remember that this binder allows you to interact with the code. You can change any part of it, but you **CANNOT** break anything. If you would like to reset the changes, you just need to re-open the binder link and everything will go back to its original state. That said, you do not necessarily need to change any code and you can obtain all the needed results by just running every cell in this binder in order. After running a code cell, you will ALWAYS see a result or output displayed just underneath it. \n",
    "\n",
    "If you plan to interact with the code, you can edit the code in the coding cell and then run that cell after the edits. If running a cell triggers a code error (this will display an error message block underneath the cell). Do not worry:\n",
    "- It is either that you changed the code and made some mistake: undo the changes and re-run the cell. \n",
    "- You skipped running some previous cells: just go back up and re-run the previous cells in order.\n",
    "- If all fails, just re-open the binder link and the environment will reset itself!\n",
    "\n",
    "For guidance, throughout the task and before any coding cell, if you see a blue <font color='Blue'>**\"You CAN edit the cell below if you want and then run it again!\"**</font>, it means that you can edit the code but only if you want.\\\n",
    "If you see an orange <font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>, it means that you do not need to edit anything and you just need to run the code to obtain the result. Again, you cannot break anything, so feel free to test and explore.\n",
    "\n",
    "If you do not want to test or edit any code, that is also fine. Just run the cells one by one without any changes and read through the binder. All the results you need are already pre-coded!\n",
    "\n",
    "<h3><center><font color='Purple'>Remember to run every code cell and afterward you should see a result displayed underneath.</font></center>\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal of this data science project is to evaluate how well an online retail store is doing and to predict the revenue growth over the next 3 years. This is a rush job from a client who is considering buying this business and you only have the daily sales data for the past 4 years to solve this problem.\n",
    "\n",
    "Based on the project goal and the data we have access to; we can frame the problem with the following questions:\n",
    "\n",
    "1. Is the business growing year-on-year or is the revenue declining?\n",
    "2. Based on the revenue growth trend (positive or negative), can we use past data to forecast the trend for the next 3 years?\n",
    "\n",
    "*Our working hypothesis:*\n",
    "\n",
    "**Hypothesis 1:** The online retail store has a positive year-on-year growth. \n",
    "\n",
    "**Hypothesis 2:** The year-on-year growth is stable enough for us to forecast revenue for the next 3 years within a precision of 10% (this is a typical precision for this retail sales forecasting).\n",
    "\n",
    "Before verifying our hypothesis, we need to explore our data to understand the features we have. This the Exploratory Data Analysis (EDA) step. We will also need to do some ETL (Extract, Transform and Load) to clear and prepare our dataset. This is an important step in data analytics and can even require more work than the actual analysis step.\n",
    "\n",
    "First, let us explore our dataset and plot some key statistics which will help us understand the data and the business.\n",
    "\n",
    "## Setup the environment\n",
    "\n",
    "We will start by setting up our analytics environment by calling the required packages for this task. \n",
    "\n",
    "We will need the following libraries:\n",
    "\n",
    "* **pandas**: library for data manipulation. It will help us structure the data.\n",
    "* **sklearn**: library of different analytics models. In this case, we will use the linear regression model.\n",
    "* **matplotlib.pyplot**: plotting library. We will use this to visualise data.\n",
    "* **numpy**: array handling and mathematic library for python.\n",
    "* **datetime** and **calendar**: a package which handles date and time data formatting.\n",
    "* **scipy.stats**: this package is used for statistical calculations.\n",
    "\n",
    "Run the following cell to import the packages \n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the code cells, any text following the '#' symbol is a comment and not a command\n",
    "# comments in the code are used to help explain the commands\n",
    "# Next code line helps with displaying visuals\n",
    "%matplotlib inline   \n",
    "#Next command imports the pandas library which handles data tables\n",
    "import pandas as pd   \n",
    "#Next command imports the plotting library\n",
    "import matplotlib.pyplot as plt   \n",
    "#Next command imports the datetime library to handle date type data\n",
    "import datetime as dt  \n",
    "\n",
    "#print out import done message\n",
    "print('Packages import done!');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input data\n",
    "\n",
    "We will start by reading the sales data from a file. We will use the **pandas** library to generate a structured data table called a **dataframe**.\n",
    "\n",
    "To read the data we need the name of the data file and the location or path to where the file is stored.\n",
    "Run the next cell to read the data. We will call our dataframe retail_data.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data = pd.read_csv('./input_data/superstore_data.csv',encoding='iso-8859-1') #read the data\n",
    "print('Reading the input data done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preview the dataframe and display some basic information using **pandas** commands. Some very useful commands to know are:\\\n",
    "**retail_data.shape**: Display number of rows and columns\\\n",
    "**retail_data.head(n)** Display first n rows of the DataFrame\\\n",
    "**retail_data.tail(n)** Display last n rows of the DataFrame\\\n",
    "**retail_data.info()** Display Index, Datatype and Memory information\\\n",
    "**retail_data.describe()** Provides summary statistics for numerical columns\\\n",
    "**retail_data.colums** : Display list of dataframe attributes.\n",
    "**retail_data['column name'].unique()** : Display list of unique values for an attribute. You will need to replace 'column name' with the required attribute name.\n",
    "\n",
    "Have a go at testing these different commands in the cell below. You can just copy/paste them in the cell and then run it.\n",
    "\n",
    "<font color='Blue'>**\"You CAN edit the cell below if you want and then run it again!\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any text in a coding cell with '#' at the start is a comment and not a command\n",
    "# you can copy some of the commands from above to test here under this line. Remember to run the cell again.\n",
    "# e.g. retail_data.head(10)  # get first 10 lines of data\n",
    "\n",
    "\n",
    "print('If you put any test command in the cell above, you should see a result print out above this line.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the *retail_data.shape* and the *retail_data.head(n)*, we can check the size of the dataframe and preview the first 10 rows.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows and columns')\n",
    "print(retail_data.shape) #print out number of rows and columns\n",
    "retail_data.head(10) #print out 10 first rows of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the results above, we have a sales table with 9,800 transactions and 18 different attributes or columns.\n",
    "\n",
    "The first thing we will do is to convert the date attribute in the table to a datetime data format. This is to enable us to analyse attributes through time. Analysing time dependent attributes is called timeseries analysis. \n",
    "\n",
    "There are 2 date attributes in the dataset: 'Order Date' and ' Ship Date'. We will use 'Order Date', as it is the date that reflects the date of purchase.\n",
    "\n",
    "We need to convert the 'Order Date' attribute to a **datetime** data format which can then easily be interpreted by **pandas**.\n",
    "\n",
    "We can do this with the following command.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data['Order Date']=pd.to_datetime(retail_data['Order Date']) # convert 'Order Date' to datetime format\n",
    "retail_data.sort_values(by=['Order Date'],ignore_index=True,inplace=True) #sort the dataframe by 'Order Date'\n",
    "retail_data['Order Date'].head(10) #preview first 10 values of new date format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: some statistics\n",
    "\n",
    "Let us now explore some attributes.\n",
    "\n",
    "Can you copy the last line in the next cell and replace 'Category' by 'Sub-Category' to explore the list of products sold by this store?\n",
    "\n",
    "<font color='Blue'>**\"You CAN edit the cell below if you want and then run it again!\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the list of unique country values\n",
    "print('List of countries:',retail_data['Country'].unique()) \n",
    "#print out the list of unique states\n",
    "print('Number of states =',len(retail_data['State'].unique())) \n",
    "#print out the list of unique product categories\n",
    "print('List of product categories:',retail_data['Category'].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this online store operates only within the United States. It has served 49 states so far and it sells Furniture, Office supplies and Technology products.\n",
    "Let us push the exploration a bit further.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of transactions = ',retail_data['Order ID'].count()) # count total number of transactions\n",
    "print('Number of unique customers = ',len(retail_data['Customer ID'].unique())) # number of unique customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we can see that the number of unique customers is much smaller than the total number of transactions. This means that many customers buy multiple items which is good for the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: top sales\n",
    "\n",
    "Next in our data exploration, we can visualise the top 10 selling products by 'Sub-Category'.\n",
    "\n",
    "You can also visualise the top 10 selling products by 'Product Names'. To do so, you only need to replace in the cell below **'Sub-Category'** by **'Product Name'** and re-run the cell. There are 2 places in the code where you need to do the replacement.\n",
    "\n",
    "FYI, we put in comments in the coding cell to explain the different commands.\n",
    "\n",
    "<font color='Blue'>**\"You CAN edit the cell below if you want and then run it again!\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a line by line description of the visualisation commands:\n",
    "# sum the sales by sub-category \n",
    "# then sort the result in Descending order and \n",
    "# select the top 10 sub-category sales\n",
    "\n",
    "top10_products=retail_data.groupby(['Sub-Category'])['Sales'].sum()\\\n",
    "                .sort_values(ascending=False)\\\n",
    "                .nlargest(10).reset_index()\n",
    "                \n",
    "# plot a bar chart selecting 'Sub-Category' for x-axis and 'Sales for 'y-axis' and \n",
    "#specify rotation for x labels, the size of the figure and the title of the y-axis.\n",
    "\n",
    "ax=top10_products.plot.bar(x='Sub-Category', y='Sales', rot=45,figsize=(15,5)).set_ylabel(\"Sales in dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the bar plot, phones and chairs are the top selling sub-categories.\n",
    "\n",
    "Other interesting things you can explore, using a similar bar chart to the one above, is to check the top States for sales by grouping data by 'State', top customers by grouping the data by 'Customer ID' or top cities generating revenue by grouping by 'City'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL: sales timeseries\n",
    "\n",
    "Let us now visualise the sales data through time by plotting the 'Sales' data by 'Order Date'.\\\n",
    "Building a visual using the matplotlib package requires the use of multiple commands. Below you can see the coding cell for plotting the data.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5)) #setup the plot size\n",
    "ax.plot(retail_data['Order Date'],retail_data['Sales'],color='blue',label='Sales') # define x and y data and colour\n",
    "ax.set(xlabel='Date', ylabel='Sales in dollars', # define x and y labels\n",
    "       title='Superstores sales data') # define the title of the visual\n",
    "plt.xticks(rotation=30) # rotate date labels by 30 degrees\n",
    "plt.legend(loc=\"upper left\") # define position of the legend\n",
    "plt.show() # diplay the visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice the date range of the data and confirm that indeed we have 4 years worth of sales. Otherwise, the visual itself is very messy with too much information because we are visualising the sales at the level of every item. Looking at this, it seems hard to figure out how we can predict sales for the next 3 years! \n",
    "\n",
    "Don't worry, this is where data pre-processing or ETL can help! For our sales prediction, we do not care about product name or even categories. All we care about is the combined revenue generated, in this case, over a year. Aggregating the data by time bins can help us better visualise the revenue over longer period of times.\n",
    "\n",
    "We can aggregate data using different time bins. In this case, we can look at the sales daily (by summing sales over all products for every single day), or weekly or monthly or even yearly.\n",
    "\n",
    "The code below lets you aggregate the data daily. The time bin is selected by changing the parameter 'freq' (which is frequency).\n",
    "Some of the options for the 'freq' parameter are 'D' for daily, 'W' for weekly, 'M' for monthly and 'Y' for yearly.\n",
    "\n",
    "Go ahead and change 'freq' value to freq='W' and re-run the cell to visualise the weekly sales data. You can do the same for monthly and yearly.\n",
    "\n",
    "<font color='Blue'>**\"You CAN edit the cell below if you want and then run it again!\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the sales data by time bin. \n",
    "# The time bin is selected by changing the value of the parameter 'freq' in the first line of the code.\n",
    "aggregated_sales = retail_data.groupby(pd.Grouper(key='Order Date', freq='D'))\\\n",
    "       .sum()\\\n",
    "       .sort_values(['Order Date','Sales'],ascending=[True,False])\\\n",
    "       .reset_index()\n",
    "\n",
    "#visualise the aggregated sales\n",
    "fig, ax = plt.subplots(figsize=(15,5)) #setup plot size\n",
    "ax.plot(aggregated_sales['Order Date'],aggregated_sales['Sales'],color='blue',label='Sales') #plot data\n",
    "ax.set(xlabel='Date', ylabel='Sales in dollars', title='Superstore sales data') #define labels and title\n",
    "plt.xticks(rotation=30) #rotate labels\n",
    "plt.legend(loc=\"upper left\") #define position of the legend\n",
    "plt.show() #display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you tested different aggregation levels above, you would have noticed that the more you aggregate the easier it is to see the growth in sales. In fact, given that we only care about yearly growth, the best aggregation level in our case is monthly sales as that would remove, what we call in retail data, 'seasonality'. Seasonality introduces time patterns or variability that can be identified in the data. This is well known in retail where people tend to have preferred shopping days (for example closer to the weekend or during the weekend) and shop less at the beginning of the week. Due to this you will see sales going up at the end of the week and then going down at the start of the week. When you aggregate data monthly, you remove weekly seasonality. There is still yearly seasonality in play which is linked to the holidays, the 'Discount' periods or end of financial inventory review.  This can be removed by aggregating yearly but if we do that, we end up with only 4 data points (we only have 4 years of data) which is not enough for robust forecasting.\n",
    "\n",
    "This is what monthly aggregated sales data look like.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the sales data by month\n",
    "monthly_sales = retail_data.groupby(pd.Grouper(key='Order Date', freq='M'))\\\n",
    "       .sum()\\\n",
    "       .sort_values(['Order Date','Sales'],ascending=[True,False])\\\n",
    "       .reset_index()\n",
    "\n",
    "#visualise the aggregated sales\n",
    "fig, ax = plt.subplots(figsize=(15,5))  #setup plot size\n",
    "ax.plot(monthly_sales['Order Date'],monthly_sales['Sales'],color='blue',label='Sales') #plot data\n",
    "ax.set(xlabel='Date', ylabel='Sales in dollars',title='Superstore monthly sales data') #define labels and title\n",
    "plt.xticks(rotation=30) #rotate labels\n",
    "plt.legend(loc=\"upper left\") #define position of the legend\n",
    "plt.show() #display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is much clearer from the monthly data that the revenue from the store is growing year-on-year. We can still see yearly seasonality in the form of peak sales, specifically toward the end of the year which is the holiday season and during which there are often significant discounts and offers in place.\n",
    "\n",
    "This monthly aggregated sales data is the dataset we will use to forecast revenue growth.\n",
    "\n",
    "We will only keep the columns we care for the forecasting.\n",
    "\n",
    "<font color='Orange'>**\"You DO NOT need to edit anything in the code below! Just run the cell to see the result underneath.\"**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data=monthly_sales[['Order Date','Sales']] #select only order date and sales\n",
    "monthly_sales_data.head(10) #preview the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it for our EDA and ETL!\n",
    "\n",
    "## To conclude\n",
    "\n",
    "Throughout this task, we explored some of input data properties using EDA processes and learned to create an aggregated monthly sales dataset with ETL.\n",
    "\n",
    "The new cleaned and transformed dataset will be used as our input dataset for Task 2 where we will forecast the revenue sales over the next 3 years.\n",
    "\n",
    "<h3><center><font color='Purple'>Please take a screenshot of the last generated visual in this task (monthly aggregated sales plot). You will need it for your next Practera assessment!</font></center>\n",
    "\n",
    "    \n",
    "Time to go back to Practera for your next assessment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
